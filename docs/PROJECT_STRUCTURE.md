# ğŸ“ ConnectX Project Structure

## ğŸ¯ Design Principles

1. **Modularity**: Each component has clear responsibilities and is independently testable.
2. **Extensibility**: Easy to add new agent implementations.
3. **Standardization**: Follows Python package management best practices.
4. **Centralization**: Unified organization of outputs and documentation.

## ğŸ“‚ Complete Directory Structure

```
connectX/
â”‚
â”œâ”€â”€ ğŸ“ agents/                       # All agent implementations
â”‚   â”œâ”€â”€ __init__.py                  # Package initialization
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ base/                     # Shared base components
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py                # Base configuration class
â”‚   â”‚   â””â”€â”€ utils.py                 # Common utility functions
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ dqn/                      # Basic DQN implementation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dqn_model.py             # DQN Neural Network
â”‚   â”‚   â”œâ”€â”€ dqn_agent.py             # DQN Agent
â”‚   â”‚   â”œâ”€â”€ replay_buffer.py         # Experience Replay
â”‚   â”‚   â””â”€â”€ train_dqn.py             # Training script
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ rainbow/                  # Rainbow DQN implementation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ rainbow_config.py        # Rainbow configuration
â”‚   â”‚   â”œâ”€â”€ rainbow_model.py         # Dueling + Noisy Nets
â”‚   â”‚   â”œâ”€â”€ rainbow_agent.py         # Rainbow Agent
â”‚   â”‚   â”œâ”€â”€ prioritized_buffer.py    # Prioritized Experience Replay
â”‚   â”‚   â”œâ”€â”€ train_rainbow.py         # Training script
â”‚   â”‚   â””â”€â”€ README.md                # Rainbow documentation
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ alphazero/                # AlphaZero implementation
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ az_config.py             # AlphaZero configuration
â”‚       â”œâ”€â”€ az_model.py              # Policy-Value Network
â”‚       â”œâ”€â”€ mcts.py                  # MCTS implementation
â”‚       â”œâ”€â”€ self_play.py             # Self-play engine
â”‚       â”œâ”€â”€ train_alphazero.py       # Training script
â”‚       â””â”€â”€ README.md                # AlphaZero documentation
â”‚
â”œâ”€â”€ ğŸ“ evaluation/                   # Evaluation Framework
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ arena.py                     # Match arena
â”‚   â”œâ”€â”€ benchmark.py                 # Benchmark suite
â”‚   â””â”€â”€ compare.py                   # Performance comparison
â”‚
â”œâ”€â”€ ğŸ“ playground/                   # Interactive Game Interface
â”‚   â””â”€â”€ play.py                      # PyGame main program
â”‚
â”œâ”€â”€ ğŸ“ scripts/                      # Automation Scripts
â”‚   â”œâ”€â”€ setup_env.bat                # Windows setup script
â”‚   â””â”€â”€ setup_env.sh                 # Linux/Mac setup script
â”‚
â”œâ”€â”€ ğŸ“ tools/                        # Utility Scripts
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ prepare_submission.py        # Kaggle submission preparation
â”‚   â”œâ”€â”€ visualize.py                 # Visualization tools
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ ğŸ“ outputs/                      # Training Outputs (Unified)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ ğŸ“ checkpoints/             # Training checkpoints
â”‚   â”‚   â”œâ”€â”€ dqn/
â”‚   â”‚   â”œâ”€â”€ rainbow/
â”‚   â”‚   â””â”€â”€ alphazero/
â”‚   â”œâ”€â”€ ğŸ“ logs/                    # Training logs
â”‚   â”‚   â”œâ”€â”€ dqn/
â”‚   â”‚   â”œâ”€â”€ rainbow/
â”‚   â”‚   â””â”€â”€ alphazero/
â”‚   â”œâ”€â”€ ğŸ“ models/                  # Final models
â”‚   â”‚   â”œâ”€â”€ dqn/
â”‚   â”‚   â”œâ”€â”€ rainbow/
â”‚   â”‚   â””â”€â”€ alphazero/
â”‚   â””â”€â”€ ğŸ“ plots/                   # Training plots
â”‚       â”œâ”€â”€ dqn/
â”‚       â”œâ”€â”€ rainbow/
â”‚       â””â”€â”€ alphazero/
â”‚
â”œâ”€â”€ ğŸ“ docs/                         # Documentation
â”‚   â”œâ”€â”€ README.md                    # Detailed documentation
â”‚   â”œâ”€â”€ QUICKSTART.md                # Quick start guide
â”‚   â”œâ”€â”€ ARCHITECTURE.md              # Architecture description
â”‚   â””â”€â”€ REORGANIZATION.md            # Reorganization plan
â”‚
â”œâ”€â”€ ğŸ“ tests/                        # Test Code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_dqn.py                  # DQN tests
â”‚   â”œâ”€â”€ test_rainbow.py              # Rainbow tests
â”‚   â”œâ”€â”€ test_alphazero.py            # AlphaZero tests
â”‚   â””â”€â”€ test_evaluation.py           # Evaluation tests
â”‚
â”œâ”€â”€ ğŸ“ experiments/                  # Experimental Results
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ ğŸ“ submission/                   # Kaggle Submission Files
â”‚   â”œâ”€â”€ dqn_agent.py
â”‚   â”œâ”€â”€ rainbow_agent.py
â”‚   â”œâ”€â”€ alphazero_agent.py
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ ğŸ“„ run_experiment.py            # Main Experiment Script
â”œâ”€â”€ ğŸ“„ cleanup_old_files.py         # Cleanup Script
â”œâ”€â”€ ğŸ“„ requirements.txt             # Dependencies
â”œâ”€â”€ ğŸ“„ .gitignore                   # Git Ignore
â”œâ”€â”€ ğŸ“„ LICENSE                      # License
â”œâ”€â”€ ğŸ“„ README.md                    # Project Main README
â”œâ”€â”€ ğŸ“„ REORGANIZATION_COMPLETE.md   # Reorganization Completion Note
â””â”€â”€ ğŸ“„ PROJECT_STRUCTURE.md         # This File
```

## ğŸ” Directory Description

### agents/ - Agent Implementations

**Role**: Contains implementations of all Reinforcement Learning agents.

**Subdirectories**:

- `base/`: Shared base components (config, utils).
- `dqn/`: Basic DQN implementation (baseline).
- `rainbow/`: Rainbow DQN (6 major improvements).
- `alphazero/`: AlphaZero (MCTS + Neural Network).

**Features**:

- Independent directory for each agent.
- Shared components in `base/`.
- Easy to add new agents.

### evaluation/ - Evaluation Framework

**Role**: Unified tool for agent evaluation and comparison.

**Components**:

- `arena.py`: Fair match platform.
- `benchmark.py`: Standardized performance testing.
- `compare.py`: Multi-agent comparison analysis.

**Features**:

- Agent-agnostic evaluation interface.
- Standardized performance metrics.
- Automatic comparison report generation.

### playground/ - Interactive Game Interface

**Role**: Provides a graphical interface to play against AI.

**Components**:

- `play.py`: PyGame-based interactive game program.

**Features**:

- Real-time gameplay.
- Visualized board.
- Supports loading trained models.

**Dependencies**: Requires `pygame` library (included in `requirements.txt`).

### scripts/ - Automation Scripts

**Role**: Provides convenient environment setup and automation tools.

**Components**:

- `setup_env.bat`: Windows environment setup script.
- `setup_env.sh`: Linux/Mac environment setup script.

**Functions**:

- Automatically creates Python virtual environment.
- Checks Python version.
- Installs all project dependencies.
- Provides clear installation feedback.

**Usage**:

```bash
# Windows
scripts\setup_env.bat

# Linux/Mac
chmod +x scripts/setup_env.sh
./scripts/setup_env.sh
```

### tools/ - Utility Scripts

**Role**: Tools for development and deployment assistance.

**Includes**:

- Kaggle submission preparation.
- Training visualization.
- Diagnostic tools.

### outputs/ - Training Outputs

**Role**: Unified management of all files generated during training.

**Structure**: Organized by agent type and output type.

- `checkpoints/`: Training checkpoints.
- `logs/`: TensorBoard logs.
- `models/`: Final trained models.
- `plots/`: Training curve plots.

**Advantages**:

- Centralized management.
- Easy to clean up.
- Convenient for backup.

### docs/ - Documentation

**Role**: Centralized management of all project documentation.

**Includes**:

- User guides.
- API documentation.
- Architecture description.
- Development documentation.

### tests/ - Tests

**Role**: Unit tests and integration tests.

**Organization**: Test files organized by module.

## ğŸš€ Usage

### Train Agent

```bash
# Using module mode
python -m agents.rainbow.train_rainbow
python -m agents.alphazero.train_alphazero

# Or run directly
python agents/rainbow/train_rainbow.py
python agents/alphazero/train_alphazero.py
```

### Run Full Experiment

```bash
# Quick test
python run_experiment.py --quick

# Full training
python run_experiment.py
```

### Evaluate Performance

```bash
# Benchmark test
python -m evaluation.benchmark

# Generate comparison report
python -m evaluation.compare
```

### Prepare Submission

```bash
python tools/prepare_submission.py \
    --agent rainbow \
    --model-path outputs/models/rainbow/best.pth
```

## ğŸ“¦ Package Import Examples

```python
# Import base components
from agents.base.config import config
from agents.base.utils import encode_state, get_valid_moves

# Import specific agent
from agents.rainbow.rainbow_agent import RainbowAgent
from agents.alphazero.mcts import MCTS

# Import evaluation tools
from evaluation.arena import Arena
from evaluation.benchmark import Benchmark
```

## ğŸ”„ Adding a New Agent

Standard process for adding a new agent:

```bash
# 1. Create directory
mkdir agents/new_agent

# 2. Create necessary files
touch agents/new_agent/__init__.py
touch agents/new_agent/new_agent_config.py
touch agents/new_agent/new_agent_model.py
touch agents/new_agent/new_agent_agent.py
touch agents/new_agent/train_new_agent.py

# 3. Inherit base components
# In code: from agents.base import config, utils

# 4. Add to evaluation
# Implement standard interface, can be directly evaluated by evaluation framework
```

## ğŸ› ï¸ Maintenance Guide

### Clean Outputs

```bash
# Clean all training outputs
rm -rf outputs/checkpoints/*
rm -rf outputs/logs/*
rm -rf outputs/plots/*

# Keep latest models
# outputs/models/ recommended to manage manually
```

### Backup Important Files

```bash
# Backup checkpoints
cp -r outputs/checkpoints/ backup/checkpoints_$(date +%Y%m%d)/

# Backup best models
cp -r outputs/models/ backup/models_$(date +%Y%m%d)/
```

### Version Control

```bash
# Track source code only, ignore outputs
git add agents/ evaluation/ tools/ docs/
git add run_experiment.py README.md requirements.txt

# outputs/ should be in .gitignore
```

## ğŸ“Š File Statistics

- **Python Files**: ~35
- **Config Files**: 3
- **Doc Files**: 8
- **Test Files**: 4 (To be improved)
- **Total Lines of Code**: ~7,500 lines

## âœ… Quality Check

### Code Style

```bash
# Format using black
black agents/ evaluation/ tools/

# Check using flake8
flake8 agents/ evaluation/ tools/

# Type check using mypy
mypy agents/
```

### Run Tests

```bash
# Run all tests
pytest tests/

# Run specific test
pytest tests/test_rainbow.py

# Generate coverage report
pytest --cov=agents tests/
```

## ğŸ¯ Best Practices

1. **Modular Development**: Develop and test each component independently.
2. **Documentation First**: Write docs before code.
3. **Test Driven**: Key features covered by tests.
4. **Version Control**: Use semantic versioning.
5. **Continuous Integration**: Automated testing and deployment.

## ğŸ“š Related Documentation

- [README.md](README.md) - Project Overview
- [docs/QUICKSTART.md](docs/QUICKSTART.md) - Quick Start
- [docs/README.md](docs/README.md) - Detailed Documentation
- [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md) - Architecture Design
- [REORGANIZATION_COMPLETE.md](REORGANIZATION_COMPLETE.md) - Reorganization Note

---
